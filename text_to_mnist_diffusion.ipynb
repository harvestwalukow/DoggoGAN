{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-Conditioned 28×28 Diffusion (MNIST-style) - IMPROVED\n",
    "\n",
    "Enhanced notebook to train and demo a text-conditioned diffusion model that generates 28×28 grayscale images using **ALL available MNIST-style datasets**. Includes improved architecture, data augmentation, and training strategies.\n",
    "\n",
    "**Key Improvements:**\n",
    "- ✓ **Multi-dataset support**: MNIST, Fashion-MNIST, KMNIST, EMNIST, QMNIST\n",
    "- ✓ **Improved architecture**: Deeper UNet with better channel multipliers and attention\n",
    "- ✓ **Data augmentation**: Random affine, rotation, scaling for better generalization\n",
    "- ✓ **Better training**: Learning rate scheduling, increased steps, improved optimizer\n",
    "\n",
    "**Contents**\n",
    "- Optional lightweight installs (including additional dataset packages)\n",
    "- Data: ALL MNIST-style datasets with diverse text prompts\n",
    "- Model: Enhanced text encoder + improved UNet with FiLM and attention\n",
    "- Diffusion training loop (classifier-free guidance ready)\n",
    "- Sampling with adjustable guidance scale and step count\n",
    "- Quick visualization grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:53:23.662358Z",
     "iopub.status.busy": "2026-01-16T09:53:23.662047Z",
     "iopub.status.idle": "2026-01-16T09:53:24.990776Z",
     "shell.execute_reply": "2026-01-16T09:53:24.989899Z",
     "shell.execute_reply.started": "2026-01-16T09:53:23.662327Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emnist\n",
      "  Using cached emnist-0.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement qmnist (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for qmnist\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Optional: install dependencies (usually available in most ML envs)\n",
    "# !pip install torch torchvision tqdm matplotlib\n",
    "# For additional MNIST datasets:\n",
    "!pip install emnist qmnist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:53:24.992759Z",
     "iopub.status.busy": "2026-01-16T09:53:24.992523Z",
     "iopub.status.idle": "2026-01-16T09:53:27.931598Z",
     "shell.execute_reply": "2026-01-16T09:53:27.930842Z",
     "shell.execute_reply.started": "2026-01-16T09:53:24.992733Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda | GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# -----------------\n",
    "# Speed preset\n",
    "# -----------------\n",
    "FAST_MODE = True  # set False for max quality\n",
    "\n",
    "# Device / seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device, '| GPUs:', torch.cuda.device_count())\n",
    "\n",
    "# GPU perf toggles (help a lot on T4)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision('high')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:53:27.932961Z",
     "iopub.status.busy": "2026-01-16T09:53:27.932619Z",
     "iopub.status.idle": "2026-01-16T09:53:28.932838Z",
     "shell.execute_reply": "2026-01-16T09:53:28.932132Z",
     "shell.execute_reply.started": "2026-01-16T09:53:27.932938Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST datasets...\n",
      "✓ KMNIST loaded: 60000 samples\n",
      "✓ EMNIST loaded: 697932 samples\n",
      "✗ QMNIST not available (may need: pip install qmnist): No module named 'qmnist'\n",
      "\n",
      "✓ Total dataset size: 877932 samples | batch_size: 512\n",
      "  - MNIST: 60000\n",
      "  - Fashion-MNIST: 60000\n",
      "  - KMNIST: 60000\n",
      "  - EMNIST: 697932\n"
     ]
    }
   ],
   "source": [
    "# Data: ALL MNIST-style datasets with text prompts\n",
    "# We train on (image, prompt) pairs so the model learns real text conditioning.\n",
    "\n",
    "MNIST_NAMES = [\n",
    "    \"zero\", \"one\", \"two\", \"three\", \"four\",\n",
    "    \"five\", \"six\", \"seven\", \"eight\", \"nine\",\n",
    "]\n",
    "FASHION_NAMES = [\n",
    "    \"t-shirt/top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
    "    \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\",\n",
    "]\n",
    "# KMNIST (Kuzushiji-MNIST) - Japanese cursive characters\n",
    "KMNIST_NAMES = [\n",
    "    \"o\", \"ki\", \"su\", \"tsu\", \"na\", \"ha\", \"ma\", \"ya\", \"re\", \"wo\"\n",
    "]\n",
    "# EMNIST Letters (A-Z, a-z) - we'll use ByClass split\n",
    "EMNIST_LETTERS = [chr(i) for i in range(ord('A'), ord('Z')+1)] + [chr(i) for i in range(ord('a'), ord('z')+1)]\n",
    "\n",
    "MNIST_TEMPLATES = [\n",
    "    \"digit {name}\",\n",
    "    \"handwritten digit {name}\",\n",
    "    \"number {name}\",\n",
    "]\n",
    "FASHION_TEMPLATES = [\n",
    "    \"fashion {name}\",\n",
    "    \"clothing {name}\",\n",
    "    \"apparel {name}\",\n",
    "]\n",
    "KMNIST_TEMPLATES = [\n",
    "    \"japanese character {name}\",\n",
    "    \"kuzushiji {name}\",\n",
    "    \"cursive {name}\",\n",
    "]\n",
    "EMNIST_TEMPLATES = [\n",
    "    \"letter {name}\",\n",
    "    \"character {name}\",\n",
    "    \"alphabet {name}\",\n",
    "]\n",
    "\n",
    "def prompt_mnist(y: int) -> str:\n",
    "    name = MNIST_NAMES[int(y)]\n",
    "    return random.choice(MNIST_TEMPLATES).format(name=name)\n",
    "\n",
    "def prompt_fashion(y: int) -> str:\n",
    "    name = FASHION_NAMES[int(y)]\n",
    "    return random.choice(FASHION_TEMPLATES).format(name=name)\n",
    "\n",
    "def prompt_kmnist(y: int) -> str:\n",
    "    name = KMNIST_NAMES[int(y)]\n",
    "    return random.choice(KMNIST_TEMPLATES).format(name=name)\n",
    "\n",
    "def prompt_emnist(y: int) -> str:\n",
    "    # EMNIST ByClass has 62 classes (A-Z, a-z, 0-9)\n",
    "    # For simplicity, map to letters if available\n",
    "    if y < len(EMNIST_LETTERS):\n",
    "        name = EMNIST_LETTERS[int(y)]\n",
    "    else:\n",
    "        # Fallback to digit names for 0-9\n",
    "        digit_idx = y - len(EMNIST_LETTERS)\n",
    "        if 0 <= digit_idx < 10:\n",
    "            name = MNIST_NAMES[digit_idx]\n",
    "        else:\n",
    "            name = f\"class_{y}\"\n",
    "    return random.choice(EMNIST_TEMPLATES).format(name=name)\n",
    "\n",
    "# Enhanced transform with data augmentation\n",
    "transform_base = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # [-1,1]\n",
    "])\n",
    "\n",
    "# Augmented transform for training (improves generalization)\n",
    "# Reduced augmentation strength for better quality - too much can hurt 28x28 images\n",
    "transform_aug = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=5, translate=(0.05, 0.05), scale=(0.95, 1.05)),  # Reduced from 10/0.1/0.9-1.1\n",
    "    transforms.RandomRotation(degrees=3),  # Reduced from 5\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # [-1,1]\n",
    "])\n",
    "\n",
    "class PromptedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_ds, prompt_fn, use_augmentation=False):\n",
    "        self.base_ds = base_ds\n",
    "        self.prompt_fn = prompt_fn\n",
    "        self.use_augmentation = use_augmentation\n",
    "    def __len__(self):\n",
    "        return len(self.base_ds)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.base_ds[idx]\n",
    "        # Apply augmentation if enabled (randomly)\n",
    "        # Note: base_ds already applies transform_base, so x is a tensor in [-1, 1]\n",
    "        if self.use_augmentation and random.random() < 0.5:\n",
    "            # Denormalize to [0, 1] for PIL conversion\n",
    "            x_denorm = (x + 1.0) / 2.0\n",
    "            x_denorm = torch.clamp(x_denorm, 0, 1)\n",
    "            x_pil = transforms.ToPILImage()(x_denorm)\n",
    "            # Apply augmentation (includes normalization back to [-1, 1])\n",
    "            x = transform_aug(x_pil)\n",
    "        # x is already normalized from base_ds transform\n",
    "        return x, self.prompt_fn(y)\n",
    "\n",
    "# Load all available MNIST-style datasets\n",
    "print(\"Loading MNIST datasets...\")\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform_base)\n",
    "fashion_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform_base)\n",
    "\n",
    "# Try to load KMNIST (Kuzushiji-MNIST)\n",
    "try:\n",
    "    kmnist_train = datasets.KMNIST(root='./data', train=True, download=True, transform=transform_base)\n",
    "    print(f\"✓ KMNIST loaded: {len(kmnist_train)} samples\")\n",
    "    kmnist_available = True\n",
    "except Exception as e:\n",
    "    print(f\"✗ KMNIST not available: {e}\")\n",
    "    kmnist_available = False\n",
    "\n",
    "# Try to load EMNIST (Extended MNIST)\n",
    "try:\n",
    "    emnist_train = datasets.EMNIST(root='./data', split='byclass', train=True, download=True, transform=transform_base)\n",
    "    print(f\"✓ EMNIST loaded: {len(emnist_train)} samples\")\n",
    "    emnist_available = True\n",
    "except Exception as e:\n",
    "    print(f\"✗ EMNIST not available: {e}\")\n",
    "    emnist_available = False\n",
    "\n",
    "# Try to load QMNIST (if available via custom loader)\n",
    "qmnist_available = False\n",
    "try:\n",
    "    # QMNIST might need special handling - try importing\n",
    "    import qmnist\n",
    "    qmnist_train = qmnist.QMNIST(root='./data', train=True, download=True, transform=transform_base)\n",
    "    print(f\"✓ QMNIST loaded: {len(qmnist_train)} samples\")\n",
    "    qmnist_available = True\n",
    "except Exception as e:\n",
    "    print(f\"✗ QMNIST not available (may need: pip install qmnist): {e}\")\n",
    "    qmnist_available = False\n",
    "\n",
    "# Combine all available datasets\n",
    "datasets_list = [\n",
    "    PromptedDataset(mnist_train, prompt_mnist, use_augmentation=True),\n",
    "    PromptedDataset(fashion_train, prompt_fashion, use_augmentation=True),\n",
    "]\n",
    "\n",
    "if kmnist_available:\n",
    "    datasets_list.append(PromptedDataset(kmnist_train, prompt_kmnist, use_augmentation=True))\n",
    "\n",
    "if emnist_available:\n",
    "    datasets_list.append(PromptedDataset(emnist_train, prompt_emnist, use_augmentation=True))\n",
    "\n",
    "train_ds = torch.utils.data.ConcatDataset(datasets_list)\n",
    "\n",
    "# Reduced batch size for larger model (will use gradient accumulation instead)\n",
    "batch_size = (256 if FAST_MODE else 128) if torch.cuda.is_available() else 64\n",
    "print(f'\\n✓ Total dataset size: {len(train_ds)} samples | batch_size: {batch_size}')\n",
    "print(f'  - MNIST: {len(mnist_train)}')\n",
    "print(f'  - Fashion-MNIST: {len(fashion_train)}')\n",
    "if kmnist_available:\n",
    "    print(f'  - KMNIST: {len(kmnist_train)}')\n",
    "if emnist_available:\n",
    "    print(f'  - EMNIST: {len(emnist_train)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:53:28.934716Z",
     "iopub.status.busy": "2026-01-16T09:53:28.934453Z",
     "iopub.status.idle": "2026-01-16T09:53:28.961226Z",
     "shell.execute_reply": "2026-01-16T09:53:28.960594Z",
     "shell.execute_reply.started": "2026-01-16T09:53:28.934692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Building blocks: time embedding, text encoder, FiLM-UNet\n",
    "\n",
    "@dataclass\n",
    "class DiffusionConfig:\n",
    "    img_size: int = 28\n",
    "\n",
    "    # model - improved architecture\n",
    "    base_channels: int = 32  # FAST default (64 for quality mode)\n",
    "    channel_mults: tuple = (1, 2, 4)  # Increased depth for better capacity\n",
    "    text_dim: int = 128\n",
    "    time_dim: int = 128\n",
    "    use_attn: bool = False  # Enable in quality mode\n",
    "    attn_heads: int = 4\n",
    "    num_layers_text: int = 3  # Deeper text encoder for better conditioning\n",
    "    dropout: float = 0.1\n",
    "\n",
    "    # diffusion - improved schedule\n",
    "    timesteps: int = 200\n",
    "    schedule: str = 'cosine'  # 'cosine' | 'linear'\n",
    "    beta_start: float = 1e-4\n",
    "    beta_end: float = 0.02\n",
    "    # Better noise schedule parameters for cleaner generation\n",
    "\n",
    "def sinusoidal_time_embedding(timesteps: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(-math.log(10000) * torch.arange(half, device=timesteps.device) / (half - 1))\n",
    "    args = timesteps[:, None] * freqs[None, :]\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "    return emb\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_dim: int, hidden_dim: int, num_layers: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        # Deeper GRU for better text understanding\n",
    "        self.gru = nn.GRU(emb_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        # Deeper projection for better text representation\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim * 2), \n",
    "            nn.SiLU(), \n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        )\n",
    "    def forward(self, tokens, lengths):\n",
    "        x = self.embedding(tokens)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        out, _ = self.gru(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        # take last valid timestep per sequence\n",
    "        idx = (lengths - 1).clamp(min=0)\n",
    "        last = out[torch.arange(out.size(0)), idx]\n",
    "        return self.proj(last)\n",
    "\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim * 2)\n",
    "    def forward(self, x, cond):\n",
    "        scale, shift = self.linear(cond).chunk(2, dim=1)\n",
    "        return x * (1 + scale[:, :, None, None]) + shift[:, :, None, None]\n",
    "\n",
    "class SelfAttention2d(nn.Module):\n",
    "    def __init__(self, channels: int, heads: int = 4):\n",
    "        super().__init__()\n",
    "        assert channels % heads == 0, 'channels must be divisible by heads'\n",
    "        self.heads = heads\n",
    "        self.norm = nn.GroupNorm(8, channels)\n",
    "        self.qkv = nn.Conv2d(channels, channels * 3, 1)\n",
    "        self.proj = nn.Conv2d(channels, channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        x_in = x\n",
    "        x = self.norm(x)\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v = qkv.chunk(3, dim=1)\n",
    "\n",
    "        # (B, heads, C//heads, HW)\n",
    "        q = q.view(b, self.heads, c // self.heads, h * w)\n",
    "        k = k.view(b, self.heads, c // self.heads, h * w)\n",
    "        v = v.view(b, self.heads, c // self.heads, h * w)\n",
    "\n",
    "        q = q.permute(0, 1, 3, 2)  # (B, heads, HW, d)\n",
    "        k = k.permute(0, 1, 2, 3)  # (B, heads, d, HW)\n",
    "        attn = (q @ k) / math.sqrt(c // self.heads)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        v = v.permute(0, 1, 3, 2)  # (B, heads, HW, d)\n",
    "        out = attn @ v\n",
    "        out = out.permute(0, 1, 3, 2).contiguous().view(b, c, h, w)\n",
    "        out = self.proj(out)\n",
    "        return x_in + out\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_dim, text_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        self.time_film = FiLM(time_dim, out_ch)\n",
    "        self.text_film = FiLM(text_dim, out_ch)\n",
    "        self.act = nn.SiLU()\n",
    "        self.norm1 = nn.GroupNorm(8, out_ch)\n",
    "        self.norm2 = nn.GroupNorm(8, out_ch)\n",
    "        self.skip = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x, t_emb, txt_emb):\n",
    "        h = self.act(self.norm1(self.conv1(x)))\n",
    "        h = self.time_film(h, t_emb)\n",
    "        h = self.text_film(h, txt_emb)\n",
    "        h = self.act(self.norm2(self.conv2(h)))\n",
    "        return h + self.skip(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, cfg: DiffusionConfig, text_vocab: int):\n",
    "        super().__init__()\n",
    "        ch = cfg.base_channels\n",
    "        self.text_encoder = TextEncoder(\n",
    "            text_vocab,\n",
    "            emb_dim=cfg.text_dim,\n",
    "            hidden_dim=cfg.text_dim,\n",
    "            num_layers=cfg.num_layers_text,\n",
    "            dropout=cfg.dropout,\n",
    "        )\n",
    "        self.null_text = nn.Parameter(torch.zeros(cfg.text_dim))\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(cfg.time_dim, cfg.time_dim * 4), nn.SiLU(), nn.Linear(cfg.time_dim * 4, cfg.time_dim)\n",
    "        )\n",
    "\n",
    "        Attn = (lambda c: SelfAttention2d(c, heads=cfg.attn_heads)) if cfg.use_attn else (lambda c: nn.Identity())\n",
    "\n",
    "        # Down - improved with more layers\n",
    "        self.enc1 = ResBlock(1, ch, cfg.time_dim, cfg.text_dim)\n",
    "        self.enc2 = ResBlock(ch, ch * cfg.channel_mults[1], cfg.time_dim, cfg.text_dim)\n",
    "        self.enc2_attn = Attn(ch * cfg.channel_mults[1])\n",
    "        self.enc3 = ResBlock(ch * cfg.channel_mults[1], ch * cfg.channel_mults[2], cfg.time_dim, cfg.text_dim)\n",
    "        self.enc3_attn = Attn(ch * cfg.channel_mults[2])\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "\n",
    "        # Bottleneck - deeper\n",
    "        self.mid1 = ResBlock(ch * cfg.channel_mults[2], ch * cfg.channel_mults[2], cfg.time_dim, cfg.text_dim)\n",
    "        self.mid_attn = Attn(ch * cfg.channel_mults[2])\n",
    "        self.mid2 = ResBlock(ch * cfg.channel_mults[2], ch * cfg.channel_mults[2], cfg.time_dim, cfg.text_dim)\n",
    "\n",
    "        # Up - improved skip connections\n",
    "        self.up1 = nn.ConvTranspose2d(ch * cfg.channel_mults[2], ch * cfg.channel_mults[1], 2, stride=2)\n",
    "        self.dec1 = ResBlock(ch * cfg.channel_mults[1] * 2, ch * cfg.channel_mults[1], cfg.time_dim, cfg.text_dim)\n",
    "        self.dec1_attn = Attn(ch * cfg.channel_mults[1])\n",
    "        self.up2 = nn.ConvTranspose2d(ch * cfg.channel_mults[1], ch, 2, stride=2)\n",
    "        self.dec2 = ResBlock(ch * 2, ch, cfg.time_dim, cfg.text_dim)\n",
    "\n",
    "        self.out = nn.Conv2d(ch, 1, 1)\n",
    "\n",
    "    def forward(self, x, t, txt_tokens, txt_lens, drop_text_prob: float = 0.1):\n",
    "        t_emb = self.time_mlp(sinusoidal_time_embedding(t, self.time_mlp[0].in_features))\n",
    "\n",
    "        # --- classifier-free guidance support ---\n",
    "        # During sampling we need a true unconditional path even in eval(),\n",
    "        # so drop_text_prob==1.0 forces the null embedding.\n",
    "        if drop_text_prob >= 1.0:\n",
    "            txt_emb = self.null_text[None, :].expand(x.size(0), -1)\n",
    "        else:\n",
    "            txt_emb = self.text_encoder(txt_tokens, txt_lens)\n",
    "            if self.training and drop_text_prob > 0.0:\n",
    "                mask = (torch.rand(txt_emb.size(0), device=txt_emb.device) < drop_text_prob).float()[:, None]\n",
    "                txt_emb = txt_emb * (1 - mask) + self.null_text[None, :] * mask\n",
    "\n",
    "        e1 = self.enc1(x, t_emb, txt_emb)\n",
    "        e2 = self.enc2(self.pool(e1), t_emb, txt_emb)\n",
    "        e2 = self.enc2_attn(e2)\n",
    "        e3 = self.enc3(self.pool(e2), t_emb, txt_emb)\n",
    "        e3 = self.enc3_attn(e3)\n",
    "\n",
    "        m = self.mid1(e3, t_emb, txt_emb)\n",
    "        m = self.mid_attn(m)\n",
    "        m = self.mid2(m, t_emb, txt_emb)\n",
    "\n",
    "        d1 = self.up1(m)\n",
    "        d1 = torch.cat([d1, e2], dim=1)\n",
    "        d1 = self.dec1(d1, t_emb, txt_emb)\n",
    "        d1 = self.dec1_attn(d1)\n",
    "        d2 = self.up2(d1)\n",
    "        d2 = torch.cat([d2, e1], dim=1)\n",
    "        d2 = self.dec2(d2, t_emb, txt_emb)\n",
    "        return self.out(d2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:53:28.962285Z",
     "iopub.status.busy": "2026-01-16T09:53:28.962013Z",
     "iopub.status.idle": "2026-01-16T09:53:28.985013Z",
     "shell.execute_reply": "2026-01-16T09:53:28.984248Z",
     "shell.execute_reply.started": "2026-01-16T09:53:28.962254Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 31\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer helpers (simple character-level; robust for small prompt vocab)\n",
    "\n",
    "class SimpleCharTokenizer:\n",
    "    def __init__(self, texts, pad_token='<pad>', unk_token='<unk>'):\n",
    "        chars = sorted(list({c for t in texts for c in t.lower()}))\n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        self.itos = [pad_token, unk_token] + chars\n",
    "        self.stoi = {c: i for i, c in enumerate(self.itos)}\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def encode(self, text: str, max_len: int = 32):\n",
    "        text = text.lower()\n",
    "        ids = [self.stoi.get(c, self.stoi[self.unk_token]) for c in text[:max_len]]\n",
    "        length = len(ids)\n",
    "        if length < max_len:\n",
    "            ids += [self.stoi[self.pad_token]] * (max_len - length)\n",
    "        return torch.tensor(ids, dtype=torch.long), torch.tensor(length, dtype=torch.long)\n",
    "\n",
    "    def encode_batch(self, texts, max_len: int = 32):\n",
    "        toks, lens = zip(*[self.encode(t, max_len=max_len) for t in texts])\n",
    "        return torch.stack(toks), torch.stack(lens)\n",
    "\n",
    "# Build tokenizer vocab from all datasets' templates\n",
    "all_prompts = []\n",
    "# MNIST prompts\n",
    "for i in range(10):\n",
    "    for tpl in MNIST_TEMPLATES:\n",
    "        all_prompts.append(tpl.format(name=MNIST_NAMES[i]))\n",
    "    for tpl in FASHION_TEMPLATES:\n",
    "        all_prompts.append(tpl.format(name=FASHION_NAMES[i]))\n",
    "# KMNIST prompts (if available)\n",
    "if 'kmnist_available' in globals() and kmnist_available:\n",
    "    for i in range(10):\n",
    "        for tpl in KMNIST_TEMPLATES:\n",
    "            all_prompts.append(tpl.format(name=KMNIST_NAMES[i]))\n",
    "# EMNIST prompts (if available)\n",
    "if 'emnist_available' in globals() and emnist_available:\n",
    "    for letter in EMNIST_LETTERS[:26]:  # A-Z\n",
    "        for tpl in EMNIST_TEMPLATES:\n",
    "            all_prompts.append(tpl.format(name=letter))\n",
    "\n",
    "tokenizer = SimpleCharTokenizer(all_prompts)\n",
    "print('Vocab size:', tokenizer.vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:53:28.986342Z",
     "iopub.status.busy": "2026-01-16T09:53:28.985994Z",
     "iopub.status.idle": "2026-01-16T09:53:29.008001Z",
     "shell.execute_reply": "2026-01-16T09:53:29.007488Z",
     "shell.execute_reply.started": "2026-01-16T09:53:28.986321Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 1715 | num_workers: 4\n"
     ]
    }
   ],
   "source": [
    "# Diffusion utilities\n",
    "\n",
    "def cosine_beta_schedule(timesteps: int, s: float = 0.008):\n",
    "    # From Nichol & Dhariwal 2021 (Improved DDPM)\n",
    "    # Improved with better s parameter for smoother transitions\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps, dtype=torch.float32)\n",
    "    alphas_cum = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cum = alphas_cum / alphas_cum[0]\n",
    "    betas = 1 - (alphas_cum[1:] / alphas_cum[:-1])\n",
    "    # Clamp to reasonable range to avoid numerical issues\n",
    "    return betas.clamp(1e-5, 0.999)\n",
    "\n",
    "\n",
    "class SimpleDiffusion(nn.Module):\n",
    "    \"\"\"DDPM/DDIM utilities with schedule tensors registered as buffers (so .to(device) works).\"\"\"\n",
    "    def __init__(self, cfg: DiffusionConfig):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if cfg.schedule == 'cosine':\n",
    "            betas = cosine_beta_schedule(cfg.timesteps)\n",
    "        else:\n",
    "            betas = torch.linspace(cfg.beta_start, cfg.beta_end, cfg.timesteps, dtype=torch.float32)\n",
    "\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cum = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alphas_cum', alphas_cum)\n",
    "\n",
    "    def sample_timesteps(self, batch_size: int, device: Optional[torch.device] = None):\n",
    "        if device is None:\n",
    "            device = self.betas.device\n",
    "        return torch.randint(0, self.cfg.timesteps, (batch_size,), device=device)\n",
    "\n",
    "    def add_noise(self, x0, t, noise):\n",
    "        # t: (B,) long on same device as buffers\n",
    "        sqrt_ac = self.alphas_cum[t].sqrt()[:, None, None, None]\n",
    "        sqrt_one_minus_ac = (1 - self.alphas_cum[t]).sqrt()[:, None, None, None]\n",
    "        return sqrt_ac * x0 + sqrt_one_minus_ac * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _predict_eps_cfg(self, model, x, t: int, txt_tokens, txt_lens, guidance_scale: float):\n",
    "        # classifier-free guidance\n",
    "        t_batch = torch.full((x.size(0),), t, device=x.device, dtype=torch.long)\n",
    "        eps_text = model(x, t_batch, txt_tokens, txt_lens, drop_text_prob=0.0)\n",
    "        eps_null = model(x, t_batch, txt_tokens, txt_lens, drop_text_prob=1.0)\n",
    "        return eps_null + guidance_scale * (eps_text - eps_null)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, model, x, t: int, txt_tokens, txt_lens, guidance_scale: float = 2.0):\n",
    "        \"\"\"Ancestral DDPM step (kept for reference).\"\"\"\n",
    "        eps = self._predict_eps_cfg(model, x, t, txt_tokens, txt_lens, guidance_scale)\n",
    "        beta_t = self.betas[t]\n",
    "        alpha_t = self.alphas[t]\n",
    "        alpha_cum_t = self.alphas_cum[t]\n",
    "        mean = (1 / alpha_t.sqrt()) * (x - beta_t / (1 - alpha_cum_t).sqrt() * eps)\n",
    "        if t == 0:\n",
    "            return mean\n",
    "        noise = torch.randn_like(x)\n",
    "        return mean + beta_t.sqrt() * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def ddim_step(self, model, x, t: int, t_prev: int, txt_tokens, txt_lens, guidance_scale: float = 2.0, eta: float = 0.0):\n",
    "        \"\"\"DDIM step that supports skipping timesteps cleanly.\"\"\"\n",
    "        eps = self._predict_eps_cfg(model, x, t, txt_tokens, txt_lens, guidance_scale)\n",
    "\n",
    "        ac_t = self.alphas_cum[t]\n",
    "        ac_prev = self.alphas_cum[t_prev] if t_prev >= 0 else torch.tensor(1.0, device=x.device)\n",
    "\n",
    "        # predict x0 with better numerical stability\n",
    "        sqrt_recip_alphas_cum_t = 1.0 / ac_t.sqrt()\n",
    "        sqrt_one_minus_alphas_cum_t = (1.0 - ac_t).sqrt()\n",
    "        x0 = sqrt_recip_alphas_cum_t * x - sqrt_one_minus_alphas_cum_t * eps\n",
    "        x0 = x0.clamp(-1, 1)\n",
    "\n",
    "        # DDIM variance control\n",
    "        if t_prev < 0:\n",
    "            return x0\n",
    "\n",
    "        # Improved DDIM step with better numerical stability\n",
    "        pred_dir = (1.0 - ac_prev).sqrt() * eps\n",
    "        x_prev = ac_prev.sqrt() * x0 + pred_dir\n",
    "        \n",
    "        # Add noise only if eta > 0 (DDIM vs DDPM interpolation)\n",
    "        if eta > 0:\n",
    "            sigma = eta * torch.sqrt((1 - ac_prev) / (1 - ac_t) * (1 - ac_t / ac_prev))\n",
    "            noise = torch.randn_like(x)\n",
    "            x_prev = x_prev + sigma * noise\n",
    "        \n",
    "        return x_prev\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, txt_tokens, txt_lens, steps: int = 40, guidance_scale: float = 2.0, eta: float = 0.0):\n",
    "        model.eval()\n",
    "        b = txt_tokens.size(0)\n",
    "        x = torch.randn(b, 1, self.cfg.img_size, self.cfg.img_size, device=txt_tokens.device)\n",
    "\n",
    "        # choose a schedule of timesteps (descending)\n",
    "        steps = int(steps)\n",
    "        steps = max(2, min(steps, self.cfg.timesteps))\n",
    "        ts = torch.linspace(self.cfg.timesteps - 1, 0, steps, device=txt_tokens.device).long()\n",
    "\n",
    "        for i in range(len(ts)):\n",
    "            t = int(ts[i].item())\n",
    "            t_prev = int(ts[i + 1].item()) if i + 1 < len(ts) else -1\n",
    "            x = self.ddim_step(model, x, t, t_prev, txt_tokens, txt_lens, guidance_scale=guidance_scale, eta=eta)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    imgs, prompts = zip(*batch)\n",
    "    imgs = torch.stack(imgs)\n",
    "    toks, lens = tokenizer.encode_batch(prompts, max_len=32)\n",
    "    return imgs, toks, lens, list(prompts)\n",
    "\n",
    "# DataLoader (now that tokenizer + collate exist)\n",
    "num_workers = 4 if torch.cuda.is_available() else 0\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=(num_workers > 0),\n",
    "    prefetch_factor=4 if num_workers > 0 else None,\n",
    "    collate_fn=collate_batch,\n",
    ")\n",
    "print('Train batches:', len(train_loader), '| num_workers:', num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T09:53:29.009124Z",
     "iopub.status.busy": "2026-01-16T09:53:29.008867Z",
     "iopub.status.idle": "2026-01-16T10:33:20.066589Z",
     "shell.execute_reply": "2026-01-16T10:33:20.065700Z",
     "shell.execute_reply.started": "2026-01-16T09:53:29.009090Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: DiffusionConfig(img_size=28, base_channels=32, channel_mults=(1, 2, 4), text_dim=128, time_dim=128, use_attn=False, attn_heads=4, num_layers_text=2, dropout=0.1, timesteps=300, schedule='cosine', beta_start=0.0001, beta_end=0.02)\n",
      "torch.compile enabled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b86c78783d456190fb581608643ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0116 09:53:41.397000 6229 torch/_inductor/utils.py:1436] [3/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training steps: 20000\n"
     ]
    }
   ],
   "source": [
    "# Model + training loop\n",
    "\n",
    "cfg = DiffusionConfig()\n",
    "\n",
    "# FAST/quality presets - SIGNIFICANTLY IMPROVED for multi-dataset training\n",
    "# Model was too small - need much more capacity for diverse datasets\n",
    "if not FAST_MODE:\n",
    "    cfg.base_channels = 96  # Increased from 64\n",
    "    cfg.use_attn = True\n",
    "    cfg.timesteps = 500\n",
    "    cfg.channel_mults = (1, 2, 4, 4)\n",
    "    cfg.text_dim = 256  # Larger text encoder\n",
    "    cfg.time_dim = 256\n",
    "else:\n",
    "    cfg.base_channels = 64  # DOUBLED from 32 - critical for quality\n",
    "    cfg.use_attn = True  # ENABLE attention even in fast mode - essential!\n",
    "    cfg.timesteps = 400  # Increased from 300\n",
    "    cfg.channel_mults = (1, 2, 4, 4)  # Deeper even in fast mode\n",
    "    cfg.text_dim = 192  # Larger text encoder\n",
    "    cfg.time_dim = 192\n",
    "\n",
    "print('Config:', cfg)\n",
    "\n",
    "diffusion = SimpleDiffusion(cfg).to(device)\n",
    "\n",
    "# Note: for this tiny 28×28 model, nn.DataParallel often *slows down*.\n",
    "# We'll default to single-GPU fast path; you can force DataParallel if you want.\n",
    "USE_DATAPARALLEL = False\n",
    "\n",
    "base_model = UNet(cfg, text_vocab=tokenizer.vocab_size).to(device)\n",
    "\n",
    "if USE_DATAPARALLEL and torch.cuda.device_count() > 1:\n",
    "    print('Using DataParallel on', torch.cuda.device_count(), 'GPUs')\n",
    "    model = nn.DataParallel(base_model)\n",
    "else:\n",
    "    model = base_model\n",
    "\n",
    "# channels_last can speed convs on some GPUs\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "# optional torch.compile (PyTorch 2.x) - can speed up steady-state\n",
    "USE_COMPILE = FAST_MODE\n",
    "if USE_COMPILE and hasattr(torch, 'compile'):\n",
    "    try:\n",
    "        model = torch.compile(model)\n",
    "        print('torch.compile enabled')\n",
    "    except Exception as e:\n",
    "        print('torch.compile failed:', e)\n",
    "\n",
    "# Improved optimizer with learning rate scheduling\n",
    "# Better LR schedule for larger model\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=2e-4 if FAST_MODE else 1e-4,  # Slightly higher for larger model\n",
    "    weight_decay=1e-2,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# EMA helps samples look cleaner with the same number of training steps\n",
    "@torch.no_grad()\n",
    "def unwrap(m: nn.Module) -> nn.Module:\n",
    "    # Handle torch.compile (stores original in _orig_mod)\n",
    "    if hasattr(m, '_orig_mod'):\n",
    "        m = m._orig_mod\n",
    "    # Handle DataParallel (stores original in .module)\n",
    "    if hasattr(m, 'module'):\n",
    "        m = m.module\n",
    "    return m\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(ema_model: nn.Module, model: nn.Module, decay: float = 0.9995):\n",
    "    src = unwrap(model)\n",
    "    for ema_p, p in zip(ema_model.parameters(), src.parameters()):\n",
    "        ema_p.data.mul_(decay).add_(p.data, alpha=1 - decay)\n",
    "\n",
    "ema_model = UNet(cfg, text_vocab=tokenizer.vocab_size).to(device)\n",
    "ema_model.load_state_dict(unwrap(model).state_dict())\n",
    "# Slightly lower EMA decay for faster adaptation during training\n",
    "ema_decay = 0.9995  # Increased from 0.999 for better quality\n",
    "\n",
    "# Mixed precision for speed on T4 (fixed deprecated API)\n",
    "if torch.cuda.is_available():\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "else:\n",
    "    scaler = None\n",
    "\n",
    "# SIGNIFICANTLY increased training steps - model needs more time to learn\n",
    "# With 877K samples across diverse datasets, need much more training\n",
    "num_steps = 40_000 if FAST_MODE else 120_000\n",
    "log_interval = 200\n",
    "\n",
    "# Learning rate scheduler for better convergence (initialized after num_steps)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=num_steps,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Gradient accumulation - use more for larger model\n",
    "grad_accum = 2 if FAST_MODE else 4  # Increased for stability with larger model\n",
    "\n",
    "model.train()\n",
    "step = 0\n",
    "pbar = tqdm(total=num_steps, desc='train')\n",
    "while step < num_steps:\n",
    "    for x, tokens, lens, _prompts in train_loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        tokens = tokens.to(device, non_blocking=True)\n",
    "        lens = lens.to(device, non_blocking=True)\n",
    "\n",
    "        # channels_last input (must match model memory_format)\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.contiguous(memory_format=torch.channels_last)\n",
    "\n",
    "        t = diffusion.sample_timesteps(x.size(0), device)\n",
    "        noise = torch.randn_like(x)\n",
    "        x_noisy = diffusion.add_noise(x, t, noise)\n",
    "\n",
    "        # gradient accumulation\n",
    "        if step % grad_accum == 0:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Fixed deprecated API - use torch.amp.autocast\n",
    "        autocast_context = torch.amp.autocast('cuda', enabled=torch.cuda.is_available()) if torch.cuda.is_available() else torch.amp.autocast('cpu', enabled=False)\n",
    "        with autocast_context:\n",
    "            pred = model(x_noisy, t, tokens, lens, drop_text_prob=0.1)\n",
    "            # CRITICAL: Use standard MSE loss for epsilon prediction\n",
    "            # This is the most common and effective loss for diffusion models\n",
    "            # Simple MSE works best - SNR weighting can sometimes hurt\n",
    "            loss = F.mse_loss(pred, noise)\n",
    "            loss = loss / grad_accum\n",
    "\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        if (step + 1) % grad_accum == 0:\n",
    "            if scaler is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            # CRITICAL FIX: scheduler.step() must be called AFTER optimizer.step()\n",
    "            # This ensures the first LR value is not skipped\n",
    "            scheduler.step()\n",
    "            ema_update(ema_model, model, decay=ema_decay)\n",
    "\n",
    "        step += 1\n",
    "        pbar.update(1)\n",
    "        if step % log_interval == 0:\n",
    "            pbar.set_postfix(loss=float(loss.detach()) * grad_accum)\n",
    "        if step >= num_steps:\n",
    "            break\n",
    "pbar.close()\n",
    "print('Finished training steps:', step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T10:33:45.877669Z",
     "iopub.status.busy": "2026-01-16T10:33:45.876849Z",
     "iopub.status.idle": "2026-01-16T10:33:46.771693Z",
     "shell.execute_reply": "2026-01-16T10:33:46.771116Z",
     "shell.execute_reply.started": "2026-01-16T10:33:45.877636Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x200 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sampling demo\n",
    "# Use EMA weights for nicer samples\n",
    "ema_model.eval()\n",
    "\n",
    "# Demo prompts (all dataset types)\n",
    "prompts = [\n",
    "    \"digit zero\",\n",
    "    \"digit three\",\n",
    "    \"digit seven\",\n",
    "    \"fashion sneaker\",\n",
    "    \"fashion ankle boot\",\n",
    "]\n",
    "# Add prompts for other datasets if available\n",
    "if 'kmnist_available' in globals() and kmnist_available:\n",
    "    prompts.extend([\"japanese character o\", \"kuzushiji ki\"])\n",
    "if 'emnist_available' in globals() and emnist_available:\n",
    "    prompts.extend([\"letter A\", \"letter Z\"])\n",
    "\n",
    "tokens = []\n",
    "lens = []\n",
    "for p in prompts:\n",
    "    tok, l = tokenizer.encode(p)\n",
    "    tokens.append(tok)\n",
    "    lens.append(l)\n",
    "tokens = torch.stack(tokens).to(device)\n",
    "lens = torch.stack(lens).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # CRITICAL: Much more sampling steps for better quality\n",
    "    # With larger model and better training, can use more steps\n",
    "    samples = diffusion.sample(ema_model, tokens, lens, steps=100, guidance_scale=3.5, eta=0.0)\n",
    "\n",
    "imgs = (samples.clamp(-1, 1) * 0.5 + 0.5).cpu()  # back to [0,1]\n",
    "fig, axes = plt.subplots(1, len(prompts), figsize=(len(prompts)*2, 2))\n",
    "for ax, img, p in zip(axes, imgs, prompts):\n",
    "    ax.imshow(img[0], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(p)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAJOR Improvements (v3) - Model Was Too Small!\n",
    "\n",
    "### Critical Architecture Changes\n",
    "- ✅ **DOUBLED model size**: 32 → 64 base channels in fast mode (was way too small!)\n",
    "- ✅ **ENABLED attention in fast mode**: Essential for quality, was disabled before\n",
    "- ✅ **Deeper network**: (1,2,4,4) channel mults even in fast mode (was (1,2,4))\n",
    "- ✅ **Larger text encoder**: 192 dim (fast) / 256 dim (quality) vs 128\n",
    "- ✅ **Deeper text encoder**: 3 layers vs 2 for better conditioning\n",
    "- ✅ **Better text projection**: 2-layer MLP instead of simple projection\n",
    "\n",
    "### Training Improvements\n",
    "- ✅ **SNR-weighted MSE loss**: Proper diffusion loss (was using Smooth L1)\n",
    "- ✅ **2x more training steps**: 40K (fast) / 120K (quality) vs 20K / 80K\n",
    "- ✅ **More sampling steps**: 100 steps vs 50 for much better quality\n",
    "- ✅ **Higher guidance**: 3.5 vs 3.0 for stronger text conditioning\n",
    "- ✅ **Better DDIM sampling**: Improved numerical stability\n",
    "- ✅ **More gradient accumulation**: 2 (fast) / 4 (quality) for stability\n",
    "\n",
    "### Why Results Were Poor\n",
    "The model was **severely undercapacity** for the diverse 877K sample dataset:\n",
    "- 32 base channels with no attention = too small\n",
    "- Wrong loss function (Smooth L1 instead of SNR-weighted MSE)\n",
    "- Not enough training steps for dataset size\n",
    "- Too few sampling steps\n",
    "\n",
    "## Critical Fixes Applied (v2)\n",
    "\n",
    "### Bug Fixes\n",
    "- ✅ **Fixed scheduler order bug**: `scheduler.step()` now called AFTER `optimizer.step()` (was causing first LR to be skipped)\n",
    "- ✅ **Fixed deprecated APIs**: Updated `torch.cuda.amp.*` to `torch.amp.*` (removes FutureWarnings)\n",
    "- ✅ **Improved loss function**: Changed from MSE to Smooth L1 (Huber loss) for more robust training\n",
    "- ✅ **Reduced classifier-free dropout**: 0.15 → 0.1 for better text conditioning\n",
    "\n",
    "### Training Quality Improvements\n",
    "- ✅ **More training steps**: 20K (fast) / 80K (quality) vs 15K / 60K\n",
    "- ✅ **Better learning rate**: Reduced to 1.5e-4 (fast) / 8e-5 (quality) for stability\n",
    "- ✅ **More diffusion timesteps**: 300 (fast) / 500 (quality) vs 200 / 400\n",
    "- ✅ **Better EMA decay**: 0.9995 vs 0.999 for faster adaptation\n",
    "- ✅ **Reduced data augmentation**: Less aggressive transforms (28x28 images are small)\n",
    "- ✅ **Better sampling**: 50 steps, guidance_scale=3.0 (vs 40 steps, 2.0)\n",
    "\n",
    "## Improvements Made\n",
    "\n",
    "### Multi-Dataset Support\n",
    "- ✓ **MNIST** - Original handwritten digits (60K samples)\n",
    "- ✓ **Fashion-MNIST** - Clothing items (60K samples)\n",
    "- ✓ **KMNIST** - Japanese cursive characters (60K samples, if available)\n",
    "- ✓ **EMNIST** - Extended MNIST with letters (697K samples, if available)\n",
    "- ✓ **QMNIST** - Cleaned/expanded variant (if available via `pip install qmnist`)\n",
    "\n",
    "### Model Architecture Improvements\n",
    "- ✓ Deeper UNet with improved channel multipliers (1, 2, 4) vs (1, 2, 2)\n",
    "- ✓ Additional attention layers in encoder and bottleneck\n",
    "- ✓ Deeper bottleneck with two ResBlocks\n",
    "- ✓ Better skip connections throughout\n",
    "\n",
    "### Training Improvements\n",
    "- ✓ **Data augmentation**: Random affine transforms, rotation, scaling\n",
    "- ✓ **Learning rate scheduling**: Cosine annealing for better convergence\n",
    "- ✓ **Increased training steps**: 15K (fast) / 60K (quality) vs 12K / 50K\n",
    "- ✓ **Improved optimizer**: Better betas and eps settings\n",
    "\n",
    "### Tips / Next steps\n",
    "- Set `FAST_MODE = False` for maximum quality (uses attention, deeper network, more timesteps)\n",
    "- Install additional datasets: `pip install emnist qmnist` for full dataset coverage\n",
    "- Increase `num_steps` and `base_channels` for even better quality\n",
    "- Save/Load: `torch.save(model.state_dict(), 'cfdiffusion.pt')` and load with `model.load_state_dict(torch.load(...))`\n",
    "- Try more diverse prompts by expanding the tokenizer vocabulary\n",
    "- To condition on richer text, swap the GRU for a tiny Transformer encoder\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
